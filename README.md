# Тестовое задание для практикума SibmirSoft

## Взаимодействие с программой
Исполняемый скрипт - main.py, взаимодействие с которым происходит через параметры запуска (Пример строки запуска: `python main.py create_tables`). Существует 4 команды - `create_tables`, `add_new_url --url --source --name --extension`, `all_files`, `delete_url --id --url --table_name`: 
* `add_new_url` используется для добавления с таблицу информации о новом источнике данных, расположенному по пути из параметра `--url`; Параметр `--name` служит для указания названия создаваемой таблицы, а `--extension` - для указания на тип файла. `--source` используется для идентификации источника: на данный момент поддерживаются: 
  + Ссылки напрямую до файлов (get запрос к ним возвращает источник данных), для этого данный параметр можно не указывать.
  + Ссылки на файл в mail cloud (для этого указывать параметр `--source="mail"`).
* `create_tables` используется для обработки (парсинг, определения типа столбцов по заполнению, выявление первичного ключа и т.д.) данных из таблицы source (читать об архитектуре) и последующего представления их в виде таблиц в базе данных. Создаются все таблицы, которые все еще не были созданы, и заполняются данными из соответствующих файлов.
* `all_files` выводит таблицу с информацией о текущем состоянии таблицы `source` (то есть все обратабываемые источники данных, которые будут использоваться при вызове `create_tables`).
* `delete_url` используется для удаления запииси из таблицы `source` и для удаления соответствующей таблицы (если она была создана). Принимает `url`, `table_name`, `id` (получить можно из `all_files`), при этом достаточно всего одного параметра и хотя бы один является необходимым (без параметров будет выброшено окно помощи `ArgumentParser`).

На данный момент поддерживаются форматы: CSV, JSON. 
Требования к форматам:
* `CSV` - любой формат таблиц, единственное условие - в столбцах должны быть записаны лишь поддерживаемые типа данных.
* `JSON` - файлы этого формата должны отвечать следующей структуре: `{primary_key_1: {}, primary_key_2: {}, ...}`: уровень вложенности не больше 2-х, при этом ключи для второго уровня являются первичными в создаваемой таблице.

Типы данных PostgreSQL, корректно обрабатываемые программой: `BOOLEAN`, `INTEGER`, `BIGINT`, `DECIMAL`, `TIMESTAMP` (даты должны записываться в таком же виде, как они и храняться в PostgresSQL), `VARCHAR`. Указание других в источнике данных может привести к непредвиденному поведению программы.

## Архитектура
Есть всего одна по умолчанию инициализируемая таблица в базе данных - `source`, которая в себе хранит всю информацию про конкретный источник данных, который указывается через `add_new_url`. Данные из этой таблицы используются для создания таблиц через `create_tables`.

Конфигурация для подключаемой базы данных задается или через переменные окружения (`DB_NAME`, `DB_HOST`, `DB_USER`, `DB_PASS`, `DB_PORT`) или в `.env` файле в корне программы (указывать там аналогичные параметры).

Запуск контейнеров с приложением и базой данных происходит с помощью `docker-compose`, но перед этим необходимо собрать образ `simbir_test`: `docker build -t simbir_test .` (вместо . указывать относительный или абсолютный путь до `Dockerfile` из репозитория). Далее `compose` файл нужно собрать с помощью `docker-compose build`, а потом запустить в фоновом режиме с помощью `docker compose up -d`. Далее нужно зайти в контейнер с помощью `docker exec -it data_db_worker bash` и запустить консольное приложение с помощью `python main.py` в соответствии с используемыми командами (смотреть п. "Взаимодействие с программой"). Далее контейнеры можно остановить в ручную с помощью `docker stop` или оба разом с помощью `docker compose down`.
## Некоторые подробности о работе приложения
Определение первичного ключа работает так: ищется первый столбец, в котором все значения уникальные и нет `NULL` значений. Если тип данных этого столбца - `INTEGER`, то при создании таблицы этому полю выставляется тип `SERIAL`, иначе заданный тип.
Определение типов полей происходит по указанным в них значениям.
Вся журнилизация о работе приложения происходит в `logs/all_logs.log` с указанием соответствующего уровня и времени с помощью `logging` (при необходимости можно стандартными методами просмотреть логи с помощью `docker logs`), при этом сообщения о статусе / результате выполнения команд также пишутся в клиентскую консоль в соответствующем формате.

## Демонстрация работы приложения
